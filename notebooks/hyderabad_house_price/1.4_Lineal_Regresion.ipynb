{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d2cfa4",
   "metadata": {},
   "source": [
    "# Housing prices in Hyderabad, India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab10eea",
   "metadata": {},
   "source": [
    "## Project Objective ðŸŽ¯\n",
    "\n",
    "The objective of this project is to develop a regression model to predict housing prices in Hyderabad, India. Using features such as the property's area, location, number of bedrooms, and available amenities, the model will aim to estimate the market value of a property as accurately as possible.\n",
    "\n",
    "- This predictive model will be a valuable tool for:\n",
    "- Home Buyers and Sellers: To obtain an objective price estimate for a property.\n",
    "- Real Estate Agents: To assist with property valuation and client advisory.\n",
    "- Investors: To identify potentially undervalued or overvalued properties in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1fc8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display, Markdown\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../src/utils')\n",
    "\n",
    "\n",
    "# Utilities\n",
    "from regresion_metrics import show_model_equation, get_model_coeficients_dataframe\n",
    "\n",
    "\n",
    "training_features = pd.read_parquet('../../datasets/processed/housing_prices/hyderabad_house_price_training_features.parquet')\n",
    "training_labels = pd.read_parquet('../../datasets/processed/housing_prices/hyderabad_house_price_training_labels.parquet')\n",
    "\n",
    "test_features = pd.read_parquet('../../datasets/processed/housing_prices/hyderabad_house_price_test_features.parquet')\n",
    "test_labels= pd.read_parquet('../../datasets/processed/housing_prices/hyderabad_house_price_test_labels.parquet')\n",
    "\n",
    "target_metrics = '../../datasets/processed/housing_prices/hyderabad_house_price_metrics_summary.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a5d3e",
   "metadata": {},
   "source": [
    "## 1.1 Training default regresion model using cross validation\n",
    "\n",
    "**Problem:**\n",
    "\n",
    "We need to train the model, but we want to ensure that our training set is sufficiently representative. Furthermore, we need to obtain a reliable and stable estimate of the model's performance, as a single data split can lead to misleading results (either too optimistic or too pessimistic).\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Cross-validation is used to address this problem. By dividing the data into multiple folds (k) and iteratively training and validating on different subsets, we obtain a more robust measure of the model's generalization ability. However, the choice of k itself can influence the stability and bias of the metrics. A very low k can have high bias, while a very high k can have high variance. Therefore, it is justified to experiment with different values of k to understand how this parameter affects the perceived performance of our model (measured by RÂ² and RMSE).\n",
    "\n",
    "**Action:**\n",
    "\n",
    "- We will train a LinearRegression model using a Pipeline.\n",
    "- We will use the cross_validate function to evaluate its performance with different numbers of folds: 2, 5, 10, and 100.\n",
    "- For each run, we will calculate the average R-squared (RÂ²) and Root Mean Squared Error (RMSE).\n",
    "- Finally, we will compile all the results into a single DataFrame to compare how the choice of folds affects the metrics and their standard deviation. This will help us choose a reliable cross-validation strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1172c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass # Necesitas esta clase para el esquema de mÃ©tricas\n",
    "\n",
    "@dataclass\n",
    "class RegresionMetric:\n",
    "    \"\"\"Clase para almacenar los resultados de la validaciÃ³n cruzada y retornarlos como diccionario.\"\"\"\n",
    "    model_name: str\n",
    "    r2_mean: float\n",
    "    r2_std: float\n",
    "    rmse_mean: float\n",
    "    rmse_std: float\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"Retorna los atributos de la instancia como un diccionario.\"\"\"\n",
    "        return {\n",
    "            'Model Name': self.model_name,\n",
    "            'R2 Mean': self.r2_mean,\n",
    "            'R2 Std': self.r2_std,\n",
    "            'RMSE Mean': self.rmse_mean,\n",
    "            'RMSE Std': self.rmse_std\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95fc38fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model Name': 'Default Lineal Regresion',\n",
       " 'R2 Mean': np.float64(0.865983780086094),\n",
       " 'R2 Std': np.float64(0.04510579488639769),\n",
       " 'RMSE Mean': np.float64(0.2313167010538074),\n",
       " 'RMSE Std': np.float64(0.03413525472603451)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "fold = 10\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('regresion', LinearRegression())\n",
    "])\n",
    "\n",
    "scoring_metrics = {\n",
    "    'neg_rmse': 'neg_root_mean_squared_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "cross_validate_metrics = cross_validate(estimator=pipe,\n",
    "            X=training_features,\n",
    "            y=training_labels,\n",
    "            cv=fold ,\n",
    "            scoring=scoring_metrics)\n",
    "\n",
    "metrics = RegresionMetric(\"Default Lineal Regresion\",\n",
    "                cross_validate_metrics['test_r2'].mean(),\n",
    "                cross_validate_metrics['test_r2'].std(), \n",
    "                -cross_validate_metrics['test_neg_rmse'].mean(),\n",
    "                cross_validate_metrics['test_neg_rmse'].std())\n",
    "\n",
    "metrics.to_dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d44f86",
   "metadata": {},
   "source": [
    "### 1.3 Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90ab25",
   "metadata": {},
   "source": [
    "Problem:\n",
    "\n",
    "Having too many features (high dimensionality) causes models to overfit, become unstable due to redundant data (multicollinearity), and require significant computational resources to train.\n",
    "\n",
    "Justification:\n",
    "\n",
    "PCA reduces the number of features by creating a smaller set of new, uncorrelated features called principal components. This method retains most of the original data's important information (variance) while making the model simpler, faster, and less prone to overfitting.\n",
    "\n",
    "Action:\n",
    "\n",
    "- Iterate and Select the top principal components that explain most of the variance.\n",
    "- Compare the score of the smallest component reduction and best explanation of the variance and rmse and r2_score of the initially calculated regression.\n",
    "- Transform the dataset into this new, smaller set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c6d5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('regresion', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "max_components = training_features.shape[1]\n",
    "param_grid = {\n",
    "    'pca__n_components': range(1, max_components + 1)\n",
    "}\n",
    "\n",
    "scoring_metrics = {\n",
    "    'neg_rmse': 'neg_root_mean_squared_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(training_features, training_labels)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "results_df.to_parquet(\"../../datasets/processed/metrics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5383d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
